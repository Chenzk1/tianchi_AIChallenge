{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor\n",
    "import lightgbm as lgb\n",
    "from lightgbm.plotting import plot_importance\n",
    "from lightgbm import LGBMRegressor\n",
    "from scipy import sparse\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBRegressor\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "#warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('max_colwidth',200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = os.path.join('../input')\n",
    "RAW_PATH = os.path.join(BASE_PATH, 'RAW_DATA')\n",
    "TRAIN_PATH = os.path.join(RAW_PATH, 'Metro_train')\n",
    "TEST_A_PATH = os.path.join(RAW_PATH, 'Metro_testA')\n",
    "SUBMIT_PATH = os.path.join('../submit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(props):\n",
    "    start_mem_usg = props.memory_usage().sum() / 1024**2 \n",
    "    print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n",
    "    NAlist = [] # Keeps track of columns that have missing values filled in. \n",
    "    for col in props.columns:\n",
    "        if props[col].dtype != object:  # Exclude strings\n",
    "            \n",
    "            # Print current column type\n",
    "            print(\"******************************\")\n",
    "            print(\"Column: \",col)\n",
    "            print(\"dtype before: \",props[col].dtype)\n",
    "            \n",
    "            # make variables for Int, max and min\n",
    "            IsInt = False\n",
    "            mx = props[col].max()\n",
    "            mn = props[col].min()\n",
    "            \n",
    "            # Integer does not support NA, therefore, NA needs to be filled\n",
    "            if not np.isfinite(props[col]).all(): \n",
    "                NAlist.append(col)\n",
    "                props[col].fillna(mn-1,inplace=True)  \n",
    "                   \n",
    "            # test if column can be converted to an integer\n",
    "            asint = props[col].fillna(0).astype(np.int64)\n",
    "            result = (props[col] - asint)\n",
    "            result = result.sum()\n",
    "            if result > -0.01 and result < 0.01:\n",
    "                IsInt = True\n",
    "\n",
    "            \n",
    "            # Make Integer/unsigned Integer datatypes\n",
    "            if IsInt:\n",
    "                if mn >= 0:\n",
    "                    if mx < 255:\n",
    "                        props[col] = props[col].astype(np.uint8)\n",
    "                    elif mx < 65535:\n",
    "                        props[col] = props[col].astype(np.uint16)\n",
    "                    elif mx < 4294967295:\n",
    "                        props[col] = props[col].astype(np.uint32)\n",
    "                    else:\n",
    "                        props[col] = props[col].astype(np.uint64)\n",
    "                else:\n",
    "                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n",
    "                        props[col] = props[col].astype(np.int8)\n",
    "                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n",
    "                        props[col] = props[col].astype(np.int16)\n",
    "                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n",
    "                        props[col] = props[col].astype(np.int32)\n",
    "                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n",
    "                        props[col] = props[col].astype(np.int64)    \n",
    "            \n",
    "            # Make float datatypes 32 bit\n",
    "            else:\n",
    "                props[col] = props[col].astype(np.float32)\n",
    "            \n",
    "            # Print new column type\n",
    "            print(\"dtype after: \",props[col].dtype)\n",
    "            print(\"******************************\")\n",
    "    \n",
    "    # Print final result\n",
    "    print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n",
    "    mem_usg = props.memory_usage().sum() / 1024**2 \n",
    "    print(\"Memory usage is: \",mem_usg,\" MB\")\n",
    "    print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n",
    "    return props\n",
    "def read_data(name, **params):\n",
    "    data = pd.read_csv(name, **params)\n",
    "    data = reduce_mem_usage(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of properties dataframe is : 135.62892150878906  MB\n",
      "******************************\n",
      "Column:  stationID\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  deviceID\n",
      "dtype before:  int64\n",
      "dtype after:  uint16\n",
      "******************************\n",
      "******************************\n",
      "Column:  status\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  payType\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  70.23644256591797  MB\n",
      "This is  51.78574140720163 % of the initial size\n",
      "Memory usage of properties dataframe is : 128.43527221679688  MB\n",
      "******************************\n",
      "Column:  stationID\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  deviceID\n",
      "dtype before:  int64\n",
      "dtype after:  uint16\n",
      "******************************\n",
      "******************************\n",
      "Column:  status\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  payType\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  66.51115989685059  MB\n",
      "This is  51.785742926273954 % of the initial size\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "train = pd.DataFrame()\n",
    "for file in os.listdir(TRAIN_PATH):\n",
    "    temp = read_data(os.path.join(TRAIN_PATH, file))\n",
    "    train = pd.concat([train, temp],ignore_index=True)\n",
    "    #train = train.drop(columns=['userID', 'deviceID', 'lineID', 'payType'])\n",
    "    del temp\n",
    "'''\n",
    "file = 'record_2019-01-01.csv'\n",
    "train = read_data(os.path.join(TRAIN_PATH, file))\n",
    "test_name = os.path.join(TEST_A_PATH, 'testA_record_2019-01-28.csv')\n",
    "test_28 = read_data(test_name)\n",
    "test_name = os.path.join(TEST_A_PATH, 'testA_submit_2019-01-29.csv')\n",
    "test = pd.read_csv(test_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 29号无id等信息，需要shift shift1:28->29\n",
    "train = \n",
    "\n",
    "# count,sum\n",
    "# group相当于在minute(10)上统计\n",
    "result = df.groupby(['stationID', 'week', 'weekend', 'day', 'hour', 'minute']).status.agg(['count', 'sum']).reset_index()\n",
    "\n",
    "#每10mins统计    \n",
    "# nunique\n",
    "tmp     = df.groupby(['stationID'])['deviceID'].nunique().reset_index(name='nuni_deviceID_of_stationID')\n",
    "result  = result.merge(tmp, on=['stationID'], how='left')\n",
    "tmp     = df.groupby(['stationID','hour'])['deviceID'].nunique().reset_index(name='nuni_deviceID_of_stationID_hour')\n",
    "result  = result.merge(tmp, on=['stationID','hour'], how='left')\n",
    "tmp     = df.groupby(['stationID','hour','minute'])['deviceID'].nunique().\\\n",
    "                                       reset_index(name='nuni_deviceID_of_stationID_hour_minute')\n",
    "result  = result.merge(tmp, on=['stationID','hour','minute'], how='left')\n",
    "\n",
    "# \n",
    "date_info['prev_day_is_weekend'] = date_info['is_weekend'].shift().fillna(0)\n",
    "date_info['next_day_is_weekend'] = date_info['is_weekend'].shift(-1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hour_cut(data):\n",
    "    if data>= 23 or data <= 6:\n",
    "        hour_cut = 1\n",
    "    elif data>= 10 and data <= 13:\n",
    "        hour_cut = 2\n",
    "    elif data>= 18 and data <= 22:\n",
    "        hour_cut = 3\n",
    "    elif data>= 14 and data <= 17:\n",
    "        hour_cut = 4\n",
    "    else:\n",
    "        hour_cut = 5\n",
    "    return hour_cut\n",
    "def base_processing(data):\n",
    "    #data.loc[:, 'lineID'] = data.loc[:,'lineID'].map({'A':1, 'B':2, 'C':3})\n",
    "    # 采样工作日\n",
    "    #print(f'before sampling: {data.memory_usage}')\n",
    "    #data = data[((data['weekday']!=5) & (data['weekday']!=6))]\n",
    "    #print(f'after sampling: {data.memory_usage}')\n",
    "    data['startTime'] = data['time'].apply(lambda x: str(x)[:15]+ '0:00')\n",
    "    result = data.groupby(['stationID', 'startTime'])['status'].agg(['count','sum'])\n",
    "    result = result.reset_index()\n",
    "    \n",
    "    result['inNums'] = result['sum']\n",
    "    result['outNums'] = result['count'] - result['sum']\n",
    "    result['date'] = result['startTime'].apply(lambda x: int(str(x)[8:10]))\n",
    "    \n",
    "    result['startTime_'] = result['startTime'].apply(lambda x: str(x)[11:15]+ '0:00')\n",
    "    result['startTime'] = pd.to_datetime(result['startTime'],format= '%Y-%m-%d %H:%M:%S')\n",
    "    result['weekday'] = result['startTime'].dt.weekday\n",
    "    result['hour'] = result['startTime'].apply(lambda x: int(str(x)[11:13]))\n",
    "    result['hourCut'] = result['hour'].map(get_hour_cut)\n",
    "    result = result.drop(columns=['startTime', 'hour'])\n",
    "    result = result.drop(columns=['count', 'sum'])\n",
    "    # datetime -> int\n",
    "    result['startTime_'] = pd.to_datetime(result['startTime_'],format= '%H:%M:%S')\n",
    "    result['hour'] = result['startTime_'].dt.hour\n",
    "    result['minute'] = result['startTime_'].dt.minute\n",
    "    result['startTime'] = result['hour']*60 + result['minute']\n",
    "    result = result.drop(columns=['startTime_', 'hour', 'minute'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_processing_test(data):\n",
    "    #data.loc[:, 'lineID'] = data.loc[:,'lineID'].map({'A':1, 'B':2, 'C':3})\n",
    "    # 采样工作日\n",
    "    #print(f'before sampling: {data.memory_usage}')\n",
    "    #data = data[((data['weekday']!=5) & (data['weekday']!=6))]\n",
    "    #print(f'after sampling: {data.memory_usage}')\n",
    "    result = data\n",
    "    result['date'] = result['startTime'].apply(lambda x: int(str(x)[8:10]))\n",
    "    \n",
    "    result['startTime_'] = result['startTime'].apply(lambda x: str(x)[11:15]+ '0:00')\n",
    "    result['startTime'] = pd.to_datetime(result['startTime'],format= '%Y-%m-%d %H:%M:%S')\n",
    "    result['weekday'] = result['startTime'].dt.weekday\n",
    "    result['hour'] = result['startTime'].apply(lambda x: int(str(x)[11:13]))\n",
    "    result['hourCut'] = result['hour'].map(get_hour_cut)\n",
    "    result = result.drop(columns=['startTime', 'hour'])\n",
    "    # datetime -> int\n",
    "    result['startTime_'] = pd.to_datetime(result['startTime_'],format= '%H:%M:%S')\n",
    "    result['hour'] = result['startTime_'].dt.hour\n",
    "    result['minute'] = result['startTime_'].dt.minute\n",
    "    result['startTime'] = result['hour']*60 + result['minute']\n",
    "    result = result.drop(columns=['startTime_', 'hour', 'minute'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = base_processing(train)\n",
    "test_28 = base_processing(test_28)\n",
    "test_29 = base_processing_test(test_29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_29.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 17.7855\tvalid_1's l1: 18.4451\n",
      "[20000]\ttraining's l1: 16.6919\tvalid_1's l1: 17.5794\n",
      "[30000]\ttraining's l1: 16.0998\tvalid_1's l1: 17.1156\n",
      "[40000]\ttraining's l1: 15.7\tvalid_1's l1: 16.79\n",
      "[50000]\ttraining's l1: 15.3908\tvalid_1's l1: 16.5462\n",
      "[60000]\ttraining's l1: 15.1201\tvalid_1's l1: 16.3432\n",
      "Early stopping, best iteration is:\n",
      "[68377]\ttraining's l1: 14.9415\tvalid_1's l1: 16.2217\n",
      "fold: 1\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 17.7155\tvalid_1's l1: 18.8802\n",
      "[20000]\ttraining's l1: 16.67\tvalid_1's l1: 18.1087\n",
      "[30000]\ttraining's l1: 16.0754\tvalid_1's l1: 17.6917\n",
      "[40000]\ttraining's l1: 15.6662\tvalid_1's l1: 17.3725\n",
      "Early stopping, best iteration is:\n",
      "[48434]\ttraining's l1: 15.3766\tvalid_1's l1: 17.1783\n",
      "fold: 2\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 17.6973\tvalid_1's l1: 18.4418\n",
      "[20000]\ttraining's l1: 16.6015\tvalid_1's l1: 17.5866\n",
      "[30000]\ttraining's l1: 16.0013\tvalid_1's l1: 17.1268\n",
      "[40000]\ttraining's l1: 15.6267\tvalid_1's l1: 16.8632\n",
      "[50000]\ttraining's l1: 15.3026\tvalid_1's l1: 16.6186\n",
      "[60000]\ttraining's l1: 15.0557\tvalid_1's l1: 16.4685\n",
      "[70000]\ttraining's l1: 14.8369\tvalid_1's l1: 16.3284\n",
      "Early stopping, best iteration is:\n",
      "[76196]\ttraining's l1: 14.7166\tvalid_1's l1: 16.2498\n",
      "fold: 3\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 17.8008\tvalid_1's l1: 18.7868\n",
      "[20000]\ttraining's l1: 16.697\tvalid_1's l1: 17.9008\n",
      "[30000]\ttraining's l1: 16.1038\tvalid_1's l1: 17.3914\n",
      "[40000]\ttraining's l1: 15.6793\tvalid_1's l1: 17.0928\n",
      "[50000]\ttraining's l1: 15.3521\tvalid_1's l1: 16.8554\n",
      "[60000]\ttraining's l1: 15.0999\tvalid_1's l1: 16.7033\n",
      "[70000]\ttraining's l1: 14.875\tvalid_1's l1: 16.5379\n",
      "Early stopping, best iteration is:\n",
      "[72754]\ttraining's l1: 14.8224\tvalid_1's l1: 16.5019\n",
      "fold: 4\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 17.7086\tvalid_1's l1: 18.7683\n",
      "[20000]\ttraining's l1: 16.626\tvalid_1's l1: 17.904\n",
      "[30000]\ttraining's l1: 16.0125\tvalid_1's l1: 17.4682\n",
      "[40000]\ttraining's l1: 15.5781\tvalid_1's l1: 17.1116\n",
      "[50000]\ttraining's l1: 15.2662\tvalid_1's l1: 16.8779\n",
      "Early stopping, best iteration is:\n",
      "[57100]\ttraining's l1: 15.0825\tvalid_1's l1: 16.7821\n",
      "fold: 5\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 17.6604\tvalid_1's l1: 17.9811\n",
      "[20000]\ttraining's l1: 16.5956\tvalid_1's l1: 17.1683\n",
      "[30000]\ttraining's l1: 16.0311\tvalid_1's l1: 16.745\n",
      "[40000]\ttraining's l1: 15.6104\tvalid_1's l1: 16.4602\n",
      "[50000]\ttraining's l1: 15.2937\tvalid_1's l1: 16.2367\n",
      "Early stopping, best iteration is:\n",
      "[51085]\ttraining's l1: 15.2641\tvalid_1's l1: 16.2152\n",
      "fold: 6\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 17.7865\tvalid_1's l1: 18.7055\n",
      "[20000]\ttraining's l1: 16.7055\tvalid_1's l1: 17.8642\n",
      "[30000]\ttraining's l1: 16.081\tvalid_1's l1: 17.399\n",
      "Early stopping, best iteration is:\n",
      "[35663]\ttraining's l1: 15.8364\tvalid_1's l1: 17.2191\n",
      "fold: 7\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 17.7684\tvalid_1's l1: 18.3234\n",
      "[20000]\ttraining's l1: 16.6982\tvalid_1's l1: 17.517\n",
      "[30000]\ttraining's l1: 16.1016\tvalid_1's l1: 17.0967\n",
      "Early stopping, best iteration is:\n",
      "[36140]\ttraining's l1: 15.8514\tvalid_1's l1: 16.9092\n",
      "fold: 8\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 17.8099\tvalid_1's l1: 18.6017\n",
      "[20000]\ttraining's l1: 16.7047\tvalid_1's l1: 17.7048\n",
      "[30000]\ttraining's l1: 16.1143\tvalid_1's l1: 17.2328\n",
      "[40000]\ttraining's l1: 15.6676\tvalid_1's l1: 16.9079\n",
      "[50000]\ttraining's l1: 15.3512\tvalid_1's l1: 16.6661\n",
      "Early stopping, best iteration is:\n",
      "[59093]\ttraining's l1: 15.1192\tvalid_1's l1: 16.5027\n",
      "fold: 9\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 17.7263\tvalid_1's l1: 18.3009\n",
      "[20000]\ttraining's l1: 16.6539\tvalid_1's l1: 17.4966\n",
      "[30000]\ttraining's l1: 16.1017\tvalid_1's l1: 17.1325\n",
      "[40000]\ttraining's l1: 15.6932\tvalid_1's l1: 16.8419\n",
      "Early stopping, best iteration is:\n",
      "[42410]\ttraining's l1: 15.604\tvalid_1's l1: 16.7724\n",
      "fold: 10\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 17.8123\tvalid_1's l1: 18.5066\n",
      "[20000]\ttraining's l1: 16.7221\tvalid_1's l1: 17.617\n",
      "[30000]\ttraining's l1: 16.1005\tvalid_1's l1: 17.1238\n",
      "[40000]\ttraining's l1: 15.7021\tvalid_1's l1: 16.8687\n",
      "[50000]\ttraining's l1: 15.3868\tvalid_1's l1: 16.6551\n",
      "Early stopping, best iteration is:\n",
      "[50227]\ttraining's l1: 15.38\tvalid_1's l1: 16.6401\n",
      "fold: 11\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 17.7168\tvalid_1's l1: 18.6534\n",
      "[20000]\ttraining's l1: 16.6004\tvalid_1's l1: 17.7181\n",
      "[30000]\ttraining's l1: 16.0094\tvalid_1's l1: 17.2701\n",
      "[40000]\ttraining's l1: 15.6125\tvalid_1's l1: 16.9632\n",
      "[50000]\ttraining's l1: 15.2979\tvalid_1's l1: 16.7434\n",
      "Early stopping, best iteration is:\n",
      "[52167]\ttraining's l1: 15.2344\tvalid_1's l1: 16.6918\n",
      "fold: 12\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 17.771\tvalid_1's l1: 18.5839\n",
      "[20000]\ttraining's l1: 16.6898\tvalid_1's l1: 17.713\n",
      "[30000]\ttraining's l1: 16.0906\tvalid_1's l1: 17.2494\n",
      "Early stopping, best iteration is:\n",
      "[37179]\ttraining's l1: 15.785\tvalid_1's l1: 16.9976\n",
      "fold: 13\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 17.811\tvalid_1's l1: 19.1138\n",
      "[20000]\ttraining's l1: 16.7177\tvalid_1's l1: 18.2012\n",
      "[30000]\ttraining's l1: 16.1524\tvalid_1's l1: 17.7373\n",
      "[40000]\ttraining's l1: 15.7327\tvalid_1's l1: 17.4078\n",
      "[50000]\ttraining's l1: 15.3976\tvalid_1's l1: 17.1404\n",
      "[60000]\ttraining's l1: 15.1349\tvalid_1's l1: 16.9536\n",
      "Early stopping, best iteration is:\n",
      "[63836]\ttraining's l1: 15.0547\tvalid_1's l1: 16.9069\n",
      "fold: 14\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 17.807\tvalid_1's l1: 18.1595\n",
      "[20000]\ttraining's l1: 16.7183\tvalid_1's l1: 17.3692\n",
      "[30000]\ttraining's l1: 16.1057\tvalid_1's l1: 16.9344\n",
      "[40000]\ttraining's l1: 15.7067\tvalid_1's l1: 16.6759\n",
      "Early stopping, best iteration is:\n",
      "[47769]\ttraining's l1: 15.4565\tvalid_1's l1: 16.4775\n",
      "mae error: 18.649327097308436\n",
      "fold: 0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.3058\tvalid_1's l1: 21.2697\n",
      "[20000]\ttraining's l1: 19.2489\tvalid_1's l1: 20.4083\n",
      "[30000]\ttraining's l1: 18.678\tvalid_1's l1: 20.0461\n",
      "Early stopping, best iteration is:\n",
      "[36445]\ttraining's l1: 18.4236\tvalid_1's l1: 19.8645\n",
      "fold: 1\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.1299\tvalid_1's l1: 21.3901\n",
      "[20000]\ttraining's l1: 19.1647\tvalid_1's l1: 20.6523\n",
      "[30000]\ttraining's l1: 18.6169\tvalid_1's l1: 20.3131\n",
      "Early stopping, best iteration is:\n",
      "[30772]\ttraining's l1: 18.5726\tvalid_1's l1: 20.2946\n",
      "fold: 2\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.219\tvalid_1's l1: 21.1263\n",
      "[20000]\ttraining's l1: 19.2206\tvalid_1's l1: 20.4309\n",
      "[30000]\ttraining's l1: 18.6628\tvalid_1's l1: 20.0133\n",
      "[40000]\ttraining's l1: 18.2616\tvalid_1's l1: 19.7033\n",
      "Early stopping, best iteration is:\n",
      "[41430]\ttraining's l1: 18.2166\tvalid_1's l1: 19.6704\n",
      "fold: 3\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.2985\tvalid_1's l1: 21.3414\n",
      "[20000]\ttraining's l1: 19.263\tvalid_1's l1: 20.5751\n",
      "[30000]\ttraining's l1: 18.6791\tvalid_1's l1: 20.1767\n",
      "[40000]\ttraining's l1: 18.2492\tvalid_1's l1: 19.8736\n",
      "Early stopping, best iteration is:\n",
      "[42291]\ttraining's l1: 18.1812\tvalid_1's l1: 19.8286\n",
      "fold: 4\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.2186\tvalid_1's l1: 21.5989\n",
      "[20000]\ttraining's l1: 19.2047\tvalid_1's l1: 20.8298\n",
      "[30000]\ttraining's l1: 18.6447\tvalid_1's l1: 20.4695\n",
      "[40000]\ttraining's l1: 18.2327\tvalid_1's l1: 20.1934\n",
      "[50000]\ttraining's l1: 17.9224\tvalid_1's l1: 19.9975\n",
      "Early stopping, best iteration is:\n",
      "[49777]\ttraining's l1: 17.9276\tvalid_1's l1: 19.9942\n",
      "fold: 5\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.1691\tvalid_1's l1: 20.4763\n",
      "[20000]\ttraining's l1: 19.1562\tvalid_1's l1: 19.7454\n",
      "[30000]\ttraining's l1: 18.6293\tvalid_1's l1: 19.4138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[36135]\ttraining's l1: 18.4048\tvalid_1's l1: 19.2452\n",
      "fold: 6\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.4968\tvalid_1's l1: 21.9708\n",
      "[20000]\ttraining's l1: 19.3832\tvalid_1's l1: 21.01\n",
      "[30000]\ttraining's l1: 18.7661\tvalid_1's l1: 20.5457\n",
      "[40000]\ttraining's l1: 18.3312\tvalid_1's l1: 20.2477\n",
      "Early stopping, best iteration is:\n",
      "[44793]\ttraining's l1: 18.1727\tvalid_1's l1: 20.1434\n",
      "fold: 7\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.1345\tvalid_1's l1: 21.195\n",
      "[20000]\ttraining's l1: 19.2395\tvalid_1's l1: 20.5554\n",
      "[30000]\ttraining's l1: 18.6795\tvalid_1's l1: 20.1952\n",
      "Early stopping, best iteration is:\n",
      "[37141]\ttraining's l1: 18.3883\tvalid_1's l1: 19.9632\n",
      "fold: 8\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.1996\tvalid_1's l1: 20.6351\n",
      "[20000]\ttraining's l1: 19.2325\tvalid_1's l1: 19.9794\n",
      "[30000]\ttraining's l1: 18.6968\tvalid_1's l1: 19.6628\n",
      "Early stopping, best iteration is:\n",
      "[34450]\ttraining's l1: 18.5288\tvalid_1's l1: 19.5576\n",
      "fold: 9\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.0874\tvalid_1's l1: 20.5675\n",
      "[20000]\ttraining's l1: 19.1821\tvalid_1's l1: 19.9058\n",
      "[30000]\ttraining's l1: 18.6347\tvalid_1's l1: 19.5048\n",
      "[40000]\ttraining's l1: 18.243\tvalid_1's l1: 19.2453\n",
      "Early stopping, best iteration is:\n",
      "[40086]\ttraining's l1: 18.2407\tvalid_1's l1: 19.2389\n",
      "fold: 10\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.2218\tvalid_1's l1: 20.7232\n",
      "[20000]\ttraining's l1: 19.23\tvalid_1's l1: 20.1093\n",
      "[30000]\ttraining's l1: 18.6723\tvalid_1's l1: 19.714\n",
      "Early stopping, best iteration is:\n",
      "[36160]\ttraining's l1: 18.4206\tvalid_1's l1: 19.5551\n",
      "fold: 11\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.2984\tvalid_1's l1: 21.4635\n",
      "[20000]\ttraining's l1: 19.2356\tvalid_1's l1: 20.6651\n",
      "[30000]\ttraining's l1: 18.6675\tvalid_1's l1: 20.2963\n",
      "Early stopping, best iteration is:\n",
      "[29423]\ttraining's l1: 18.6878\tvalid_1's l1: 20.2903\n",
      "fold: 12\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.1901\tvalid_1's l1: 20.3763\n",
      "[20000]\ttraining's l1: 19.1704\tvalid_1's l1: 19.7136\n",
      "[30000]\ttraining's l1: 18.6172\tvalid_1's l1: 19.3856\n",
      "Early stopping, best iteration is:\n",
      "[32665]\ttraining's l1: 18.4862\tvalid_1's l1: 19.3009\n",
      "fold: 13\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.3123\tvalid_1's l1: 21.1705\n",
      "[20000]\ttraining's l1: 19.2979\tvalid_1's l1: 20.5067\n",
      "[30000]\ttraining's l1: 18.7269\tvalid_1's l1: 20.0854\n",
      "Early stopping, best iteration is:\n",
      "[38883]\ttraining's l1: 18.3572\tvalid_1's l1: 19.8376\n",
      "fold: 14\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.2138\tvalid_1's l1: 21.4678\n",
      "[20000]\ttraining's l1: 19.1899\tvalid_1's l1: 20.7327\n",
      "[30000]\ttraining's l1: 18.6149\tvalid_1's l1: 20.2991\n",
      "[40000]\ttraining's l1: 18.2506\tvalid_1's l1: 20.0514\n",
      "Early stopping, best iteration is:\n",
      "[41980]\ttraining's l1: 18.1843\tvalid_1's l1: 20.0131\n",
      "mae error: 76.91464066284706\n"
     ]
    }
   ],
   "source": [
    "X_train = train[['stationID', 'date', 'startTime', 'weekday','hourCut']]\n",
    "y_train_1 = train['inNums']\n",
    "y_train_2 = train['outNums']\n",
    "X_test_28 = test_28[['stationID', 'date', 'startTime', 'weekday','hourCut']]\n",
    "y_test_28_1 = test_28['inNums']\n",
    "y_test_28_2 = test_28['outNums']\n",
    "X_test_29 = test_29[['stationID', 'date', 'startTime', 'weekday','hourCut']]\n",
    "params = {\n",
    "    'bagging_freq': 10,          \n",
    "    'bagging_fraction': 0.3,   'boost_from_average':'false',   \n",
    "    'boost': 'gbdt',             \n",
    "    #'feature_fraction': 0.0405,     \n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': -1,             'metric':'mae',                \n",
    "    'min_data_in_leaf': 80, \n",
    "    'num_leaves': 13,            \n",
    "    'num_threads': -1, \n",
    "    'objective': 'regression_l1',       'verbosity': 1,\n",
    "    'num_boost_round': 10000000\n",
    "}\n",
    "NFOLD = 15\n",
    "folds = KFold(n_splits=NFOLD, random_state=134, shuffle=True)\n",
    "val_lgb1 = np.zeros(len(X_train))\n",
    "pred_lgb1 = np.zeros(len(X_test_29))\n",
    "pred_28_1 = np.zeros(len(X_test_28))\n",
    "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train_1)):\n",
    "    print(f'fold: {n_fold}')\n",
    "    trn_data = lgb.Dataset(X_train.iloc[trn_idx], y_train_1[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train.iloc[val_idx], y_train_1[val_idx])\n",
    "    \n",
    "    reg_lgb1 = lgb.train(params, trn_data, num_boost_round=2000000, valid_sets=[trn_data, val_data], verbose_eval=10000, early_stopping_rounds=600)\n",
    "    #val_lgb1[val_idx] = reg_lgb1.predict(X_train.iloc[val_idx], num_iteration=reg_lgb.best_iteration)\n",
    "    pred_lgb1 += reg_lgb1.predict(X_test_29, num_iteration=reg_lgb1.best_iteration) / NFOLD\n",
    "    pred_28_1 += reg_lgb1.predict(X_test_28, num_iteration=reg_lgb1.best_iteration) / NFOLD \n",
    "print(f'mae error: {mean_absolute_error(pred_28_1, y_test_28_1)}')\n",
    "\n",
    "folds = KFold(n_splits=NFOLD, random_state=134, shuffle=True)\n",
    "val_lgb2 = np.zeros(len(X_train))\n",
    "pred_lgb2 = np.zeros(len(X_test_29))\n",
    "pred_28_2 = np.zeros(len(X_test_28))\n",
    "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train_2)):\n",
    "    print(f'fold: {n_fold}')\n",
    "    trn_data = lgb.Dataset(X_train.iloc[trn_idx], y_train_2[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train.iloc[val_idx], y_train_2[val_idx])\n",
    "    \n",
    "    reg_lgb2 = lgb.train(params, trn_data, num_boost_round=2000000, valid_sets=[trn_data, val_data], verbose_eval=10000, early_stopping_rounds=600)\n",
    "    #val_lgb2[val_idx] = reg_lgb2.predict(X_train.iloc[val_idx], num_iteration=reg_lgb.best_iteration)\n",
    "    pred_lgb2 += reg_lgb2.predict(X_test_29, num_iteration=reg_lgb2.best_iteration) / NFOLD\n",
    "    pred_28_2 += reg_lgb2.predict(X_test_28, num_iteration=reg_lgb2.best_iteration) / NFOLD \n",
    "print(f'mae error: {mean_absolute_error(pred_28_2, y_test_28_2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.3058\tvalid_1's l1: 21.2697\n",
      "[20000]\ttraining's l1: 19.2489\tvalid_1's l1: 20.4083\n",
      "[30000]\ttraining's l1: 18.678\tvalid_1's l1: 20.0461\n",
      "Early stopping, best iteration is:\n",
      "[36445]\ttraining's l1: 18.4236\tvalid_1's l1: 19.8645\n",
      "fold: 1\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.1299\tvalid_1's l1: 21.3901\n",
      "[20000]\ttraining's l1: 19.1647\tvalid_1's l1: 20.6523\n",
      "[30000]\ttraining's l1: 18.6169\tvalid_1's l1: 20.3131\n",
      "Early stopping, best iteration is:\n",
      "[30772]\ttraining's l1: 18.5726\tvalid_1's l1: 20.2946\n",
      "fold: 2\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.219\tvalid_1's l1: 21.1263\n",
      "[20000]\ttraining's l1: 19.2206\tvalid_1's l1: 20.4309\n",
      "[30000]\ttraining's l1: 18.6628\tvalid_1's l1: 20.0133\n",
      "[40000]\ttraining's l1: 18.2616\tvalid_1's l1: 19.7033\n",
      "Early stopping, best iteration is:\n",
      "[41430]\ttraining's l1: 18.2166\tvalid_1's l1: 19.6704\n",
      "fold: 3\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.2985\tvalid_1's l1: 21.3414\n",
      "[20000]\ttraining's l1: 19.263\tvalid_1's l1: 20.5751\n",
      "[30000]\ttraining's l1: 18.6791\tvalid_1's l1: 20.1767\n",
      "[40000]\ttraining's l1: 18.2492\tvalid_1's l1: 19.8736\n",
      "Early stopping, best iteration is:\n",
      "[42291]\ttraining's l1: 18.1812\tvalid_1's l1: 19.8286\n",
      "fold: 4\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.2186\tvalid_1's l1: 21.5989\n",
      "[20000]\ttraining's l1: 19.2047\tvalid_1's l1: 20.8298\n",
      "[30000]\ttraining's l1: 18.6447\tvalid_1's l1: 20.4695\n",
      "[40000]\ttraining's l1: 18.2327\tvalid_1's l1: 20.1934\n",
      "[50000]\ttraining's l1: 17.9224\tvalid_1's l1: 19.9975\n",
      "Early stopping, best iteration is:\n",
      "[49777]\ttraining's l1: 17.9276\tvalid_1's l1: 19.9942\n",
      "fold: 5\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.1691\tvalid_1's l1: 20.4763\n",
      "[20000]\ttraining's l1: 19.1562\tvalid_1's l1: 19.7454\n",
      "[30000]\ttraining's l1: 18.6293\tvalid_1's l1: 19.4138\n",
      "Early stopping, best iteration is:\n",
      "[36135]\ttraining's l1: 18.4048\tvalid_1's l1: 19.2452\n",
      "fold: 6\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.4968\tvalid_1's l1: 21.9708\n",
      "[20000]\ttraining's l1: 19.3832\tvalid_1's l1: 21.01\n",
      "[30000]\ttraining's l1: 18.7661\tvalid_1's l1: 20.5457\n",
      "[40000]\ttraining's l1: 18.3312\tvalid_1's l1: 20.2477\n",
      "Early stopping, best iteration is:\n",
      "[44793]\ttraining's l1: 18.1727\tvalid_1's l1: 20.1434\n",
      "fold: 7\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.1345\tvalid_1's l1: 21.195\n",
      "[20000]\ttraining's l1: 19.2395\tvalid_1's l1: 20.5554\n",
      "[30000]\ttraining's l1: 18.6795\tvalid_1's l1: 20.1952\n",
      "Early stopping, best iteration is:\n",
      "[37141]\ttraining's l1: 18.3883\tvalid_1's l1: 19.9632\n",
      "fold: 8\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.1996\tvalid_1's l1: 20.6351\n",
      "[20000]\ttraining's l1: 19.2325\tvalid_1's l1: 19.9794\n",
      "[30000]\ttraining's l1: 18.6968\tvalid_1's l1: 19.6628\n",
      "Early stopping, best iteration is:\n",
      "[34450]\ttraining's l1: 18.5288\tvalid_1's l1: 19.5576\n",
      "fold: 9\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.0874\tvalid_1's l1: 20.5675\n",
      "[20000]\ttraining's l1: 19.1821\tvalid_1's l1: 19.9058\n",
      "[30000]\ttraining's l1: 18.6347\tvalid_1's l1: 19.5048\n",
      "[40000]\ttraining's l1: 18.243\tvalid_1's l1: 19.2453\n",
      "Early stopping, best iteration is:\n",
      "[40086]\ttraining's l1: 18.2407\tvalid_1's l1: 19.2389\n",
      "fold: 10\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.2218\tvalid_1's l1: 20.7232\n",
      "[20000]\ttraining's l1: 19.23\tvalid_1's l1: 20.1093\n",
      "[30000]\ttraining's l1: 18.6723\tvalid_1's l1: 19.714\n",
      "Early stopping, best iteration is:\n",
      "[36160]\ttraining's l1: 18.4206\tvalid_1's l1: 19.5551\n",
      "fold: 11\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.2984\tvalid_1's l1: 21.4635\n",
      "[20000]\ttraining's l1: 19.2356\tvalid_1's l1: 20.6651\n",
      "[30000]\ttraining's l1: 18.6675\tvalid_1's l1: 20.2963\n",
      "Early stopping, best iteration is:\n",
      "[29423]\ttraining's l1: 18.6878\tvalid_1's l1: 20.2903\n",
      "fold: 12\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.1901\tvalid_1's l1: 20.3763\n",
      "[20000]\ttraining's l1: 19.1704\tvalid_1's l1: 19.7136\n",
      "[30000]\ttraining's l1: 18.6172\tvalid_1's l1: 19.3856\n",
      "Early stopping, best iteration is:\n",
      "[32665]\ttraining's l1: 18.4862\tvalid_1's l1: 19.3009\n",
      "fold: 13\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.3123\tvalid_1's l1: 21.1705\n",
      "[20000]\ttraining's l1: 19.2979\tvalid_1's l1: 20.5067\n",
      "[30000]\ttraining's l1: 18.7269\tvalid_1's l1: 20.0854\n",
      "Early stopping, best iteration is:\n",
      "[38883]\ttraining's l1: 18.3572\tvalid_1's l1: 19.8376\n",
      "fold: 14\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.2138\tvalid_1's l1: 21.4678\n",
      "[20000]\ttraining's l1: 19.1899\tvalid_1's l1: 20.7327\n",
      "[30000]\ttraining's l1: 18.6149\tvalid_1's l1: 20.2991\n",
      "[40000]\ttraining's l1: 18.2506\tvalid_1's l1: 20.0514\n",
      "Early stopping, best iteration is:\n",
      "[41980]\ttraining's l1: 18.1843\tvalid_1's l1: 20.0131\n",
      "mae error: 21.02257397201306\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=NFOLD, random_state=134, shuffle=True)\n",
    "val_lgb2 = np.zeros(len(X_train))\n",
    "pred_lgb2 = np.zeros(len(X_test_29))\n",
    "pred_28_2 = np.zeros(len(X_test_28))\n",
    "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train_2)):\n",
    "    print(f'fold: {n_fold}')\n",
    "    trn_data = lgb.Dataset(X_train.iloc[trn_idx], y_train_2[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train.iloc[val_idx], y_train_2[val_idx])\n",
    "    \n",
    "    reg_lgb2 = lgb.train(params, trn_data, num_boost_round=2000000, valid_sets=[trn_data, val_data], verbose_eval=10000, early_stopping_rounds=600)\n",
    "    #val_lgb2[val_idx] = reg_lgb2.predict(X_train.iloc[val_idx], num_iteration=reg_lgb.best_iteration)\n",
    "    pred_lgb2 += reg_lgb2.predict(X_test_29, num_iteration=reg_lgb2.best_iteration) / NFOLD\n",
    "    pred_28_2 += reg_lgb2.predict(X_test_28, num_iteration=reg_lgb2.best_iteration) / NFOLD \n",
    "print(f'mae error: {mean_absolute_error(pred_28_2, y_test_28_2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_29['inNums'] = pred_lgb1\n",
    "test_29['outNums'] = pred_lgb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_name = os.path.join(TEST_A_PATH, 'testA_submit_2019-01-29.csv')\n",
    "submit = pd.read_csv(submit_name) \n",
    "test_29['startTime'] = submit['startTime']\n",
    "test_29[['stationID', 'startTime', 'endTime', 'inNums', 'outNums']].to_csv(SUBMIT_PATH+'/lgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame([1,2,3],columns=['a'])\n",
    "b = pd.DataFrame([1,2,3],columns=['a'])\n",
    "c = pd.concat([a,b],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a\n",
       "0  1\n",
       "1  2\n",
       "2  3\n",
       "3  1\n",
       "4  2\n",
       "5  3"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
