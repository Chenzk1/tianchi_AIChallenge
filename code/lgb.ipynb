{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor\n",
    "import lightgbm as lgb\n",
    "from lightgbm.plotting import plot_importance\n",
    "from lightgbm import LGBMRegressor\n",
    "from scipy import sparse\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBRegressor\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "#warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('max_colwidth',200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = os.path.join('../input')\n",
    "RAW_PATH = os.path.join(BASE_PATH, 'RAW_DATA')\n",
    "TRAIN_PATH = os.path.join(RAW_PATH, 'Metro_train')\n",
    "TEST_A_PATH = os.path.join(RAW_PATH, 'Metro_testA')\n",
    "SUBMIT_PATH = os.path.join('../submit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(props):\n",
    "    start_mem_usg = props.memory_usage().sum() / 1024**2 \n",
    "    print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n",
    "    NAlist = [] # Keeps track of columns that have missing values filled in. \n",
    "    for col in props.columns:\n",
    "        if props[col].dtype != object:  # Exclude strings\n",
    "            \n",
    "            # Print current column type\n",
    "            print(\"******************************\")\n",
    "            print(\"Column: \",col)\n",
    "            print(\"dtype before: \",props[col].dtype)\n",
    "            \n",
    "            # make variables for Int, max and min\n",
    "            IsInt = False\n",
    "            mx = props[col].max()\n",
    "            mn = props[col].min()\n",
    "            \n",
    "            # Integer does not support NA, therefore, NA needs to be filled\n",
    "            if not np.isfinite(props[col]).all(): \n",
    "                NAlist.append(col)\n",
    "                props[col].fillna(mn-1,inplace=True)  \n",
    "                   \n",
    "            # test if column can be converted to an integer\n",
    "            asint = props[col].fillna(0).astype(np.int64)\n",
    "            result = (props[col] - asint)\n",
    "            result = result.sum()\n",
    "            if result > -0.01 and result < 0.01:\n",
    "                IsInt = True\n",
    "\n",
    "            \n",
    "            # Make Integer/unsigned Integer datatypes\n",
    "            if IsInt:\n",
    "                if mn >= 0:\n",
    "                    if mx < 255:\n",
    "                        props[col] = props[col].astype(np.uint8)\n",
    "                    elif mx < 65535:\n",
    "                        props[col] = props[col].astype(np.uint16)\n",
    "                    elif mx < 4294967295:\n",
    "                        props[col] = props[col].astype(np.uint32)\n",
    "                    else:\n",
    "                        props[col] = props[col].astype(np.uint64)\n",
    "                else:\n",
    "                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n",
    "                        props[col] = props[col].astype(np.int8)\n",
    "                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n",
    "                        props[col] = props[col].astype(np.int16)\n",
    "                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n",
    "                        props[col] = props[col].astype(np.int32)\n",
    "                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n",
    "                        props[col] = props[col].astype(np.int64)    \n",
    "            \n",
    "            # Make float datatypes 32 bit\n",
    "            else:\n",
    "                props[col] = props[col].astype(np.float32)\n",
    "            \n",
    "            # Print new column type\n",
    "            print(\"dtype after: \",props[col].dtype)\n",
    "            print(\"******************************\")\n",
    "    \n",
    "    # Print final result\n",
    "    print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n",
    "    mem_usg = props.memory_usage().sum() / 1024**2 \n",
    "    print(\"Memory usage is: \",mem_usg,\" MB\")\n",
    "    print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n",
    "    return props\n",
    "def read_data(name, **params):\n",
    "    data = pd.read_csv(name, **params)\n",
    "    data = reduce_mem_usage(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of properties dataframe is : 128.43527221679688  MB\n",
      "******************************\n",
      "Column:  stationID\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  deviceID\n",
      "dtype before:  int64\n",
      "dtype after:  uint16\n",
      "******************************\n",
      "******************************\n",
      "Column:  status\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  payType\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  66.51115989685059  MB\n",
      "This is  51.785742926273954 % of the initial size\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lineID</th>\n",
       "      <th>stationID</th>\n",
       "      <th>deviceID</th>\n",
       "      <th>status</th>\n",
       "      <th>userID</th>\n",
       "      <th>payType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-28 00:00:04</td>\n",
       "      <td>B</td>\n",
       "      <td>33</td>\n",
       "      <td>1587</td>\n",
       "      <td>0</td>\n",
       "      <td>Aad6ad59dfdd470bfdfdb0d2959db068b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-28 00:00:04</td>\n",
       "      <td>C</td>\n",
       "      <td>63</td>\n",
       "      <td>2933</td>\n",
       "      <td>0</td>\n",
       "      <td>Bab97d7b32891b8cb5451e80b73b23d70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-28 00:00:06</td>\n",
       "      <td>C</td>\n",
       "      <td>63</td>\n",
       "      <td>2934</td>\n",
       "      <td>0</td>\n",
       "      <td>Dda829d9f38d0a28f1e4ae84a34e846dc</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-28 00:00:06</td>\n",
       "      <td>C</td>\n",
       "      <td>39</td>\n",
       "      <td>1839</td>\n",
       "      <td>0</td>\n",
       "      <td>Cc397069031ab762d75d613291cd68cda</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-28 00:00:07</td>\n",
       "      <td>B</td>\n",
       "      <td>33</td>\n",
       "      <td>1588</td>\n",
       "      <td>0</td>\n",
       "      <td>Ba83c695d27b4d376bfde3f755e4b677f</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  time lineID  stationID  deviceID  status  \\\n",
       "0  2019-01-28 00:00:04      B         33      1587       0   \n",
       "1  2019-01-28 00:00:04      C         63      2933       0   \n",
       "2  2019-01-28 00:00:06      C         63      2934       0   \n",
       "3  2019-01-28 00:00:06      C         39      1839       0   \n",
       "4  2019-01-28 00:00:07      B         33      1588       0   \n",
       "\n",
       "                              userID  payType  \n",
       "0  Aad6ad59dfdd470bfdfdb0d2959db068b        0  \n",
       "1  Bab97d7b32891b8cb5451e80b73b23d70        1  \n",
       "2  Dda829d9f38d0a28f1e4ae84a34e846dc        3  \n",
       "3  Cc397069031ab762d75d613291cd68cda        2  \n",
       "4  Ba83c695d27b4d376bfde3f755e4b677f        1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_name = os.path.join(TEST_A_PATH, 'testA_record_2019-01-28.csv')\n",
    "test_28 = read_data(test_name)\n",
    "test_28.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# payType-most\n",
    "# devideID-most two\n",
    "# userID-count(this stationID)-( nunique(userID) - nunique(userID)[payType==3])\n",
    "def get_top(df, n=1):\n",
    "    return df.sort_values()[-n:]\n",
    "tmp     = test_28.groupby(['stationID'])['deviceID'].apply(get_top,n=1).reset_index(name='most_deviceID_of_stationID')\n",
    "result  = result.merge(tmp, on=['stationID'], how='left')\n",
    "tmp     = test_28.groupby(['stationID','hour'])['deviceID'].apply(get_top,n=1).reset_index(name='most_deviceID_of_stationID&hour')\n",
    "result  = result.merge(tmp, on=['stationID','hour'], how='left')\n",
    "tmp     = test_28.groupby(['stationID','weekday','hour'])['deviceID'].apply(get_top,n=1).reset_index(name='most_deviceID_of_stationID&wh')\n",
    "result  = result.merge(tmp, on=['stationID','weekday','hour'], how='left')\n",
    "#tmp     = test_28.groupby(['stationID'])['deviceID'].apply(get_top,n=2).reset_index(name='second_deviceID_of_stationID')\n",
    "#tmp     = test_28.groupby(['stationID'])['deviceID'].apply(get_top,n=2).reset_index(name='third_deviceID_of_stationID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.DataFrame([[2,3,45],[3,2,34]],columns=['a','b','c'])\n",
    "a['a'].sort_values()[-1:].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hour_cut(data):\n",
    "    if data>= 23 or data <= 6:\n",
    "        hour_cut = 1\n",
    "    elif data>= 10 and data <= 13:\n",
    "        hour_cut = 2\n",
    "    elif data>= 18 and data <= 22:\n",
    "        hour_cut = 3\n",
    "    elif data>= 14 and data <= 17:\n",
    "        hour_cut = 4\n",
    "    else:\n",
    "        hour_cut = 5\n",
    "    return hour_cut\n",
    "def is_weekend(data):\n",
    "    if data <= 4:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "def base_processing(data):\n",
    "    #data.loc[:, 'lineID'] = data.loc[:,'lineID'].map({'A':1, 'B':2, 'C':3})\n",
    "    # 采样工作日\n",
    "    #print(f'before sampling: {data.memory_usage}')\n",
    "    #data = data[((data['weekday']!=5) & (data['weekday']!=6))]\n",
    "    #print(f'after sampling: {data.memory_usage}')\n",
    "    data['startTime'] = data['time'].apply(lambda x: str(x)[:15]+ '0:00')\n",
    "    data['day'] = data['startTime'].apply(lambda x: int(str(x)[8:10]))\n",
    "    data['hour'] = data['startTime'].apply(lambda x: int(str(x)[11:13]))\n",
    "    data['minute'] = data['startTime'].apply(lambda x: int(str(x)[14:15]+'0'))# hour+10min 10min最后可以删除\n",
    "    data['startTime'] = pd.to_datetime(data['startTime'],format= '%Y-%m-%d %H:%M:%S')\n",
    "    data['weekday'] = data['startTime'].dt.weekday\n",
    "    #result['weekend'] = result['weekday'].apply(is_weekend)\n",
    "    \n",
    "    \n",
    "    result = data.groupby(['stationID', 'startTime','day', 'hour', 'minute','weekday'])['status'].agg(['count','sum'])\n",
    "    result = result.reset_index()\n",
    "    # lineID\tstationID\tdeviceID userID payType\n",
    "    # nunique\n",
    "    tmp     = data.groupby(['stationID'])['deviceID'].nunique().reset_index(name='nuni_deviceID_of_stationID')\n",
    "    result  = result.merge(tmp, on=['stationID'], how='left')\n",
    "    tmp     = data.groupby(['stationID','hour'])['deviceID'].nunique().reset_index(name='nuni_deviceID_of_stationID_hour')\n",
    "    result  = result.merge(tmp, on=['stationID','hour'], how='left')\n",
    "    tmp     = data.groupby(['stationID','hour','minute'])['deviceID'].nunique().\\\n",
    "                                           reset_index(name='nuni_deviceID_of_stationID_hour_minute')\n",
    "    result  = result.merge(tmp, on=['stationID','hour','minute'], how='left')\n",
    "    def get_top(df, n=1):\n",
    "        return df.sort_values()[-n:].values[0]\n",
    "    tmp     = data.groupby(['stationID'])['deviceID'].apply(get_top,n=1).reset_index(name='most_deviceID_of_stationID')\n",
    "    result  = result.merge(tmp, on=['stationID'], how='left')\n",
    "\n",
    "    tmp     = data.groupby(['stationID','hour'])['deviceID'].apply(get_top,n=1).reset_index(name='most_deviceID_of_stationID&hour')\n",
    "    result  = result.merge(tmp, on=['stationID','hour'], how='left')\n",
    "\n",
    "    tmp     = data.groupby(['stationID','weekday','hour'])['deviceID'].apply(get_top,n=1).reset_index(name='most_deviceID_of_stationID&wh')\n",
    "    result  = result.merge(tmp, on=['stationID','weekday','hour'], how='left')\n",
    "\n",
    "    tmp     = data.groupby(['stationID'])['payType'].apply(get_top,n=1).reset_index(name='most_payType_of_stationID')\n",
    "    result  = result.merge(tmp, on=['stationID'], how='left')\n",
    "    tmp     = data.groupby(['stationID','hour'])['payType'].apply(get_top,n=1).reset_index(name='most_payType_of_stationID&hour')\n",
    "    result  = result.merge(tmp, on=['stationID','hour'], how='left')\n",
    "    tmp     = data.groupby(['stationID','weekday','hour'])['payType'].apply(get_top,n=1).reset_index(name='most_payType_of_stationID&wh')\n",
    "    result  = result.merge(tmp, on=['stationID','weekday','hour'], how='left')\n",
    "    \n",
    "    \n",
    "    result['inNums'] = result['sum']\n",
    "    result['outNums'] = result['count'] - result['sum']\n",
    "    \n",
    "    #result['weekday'] = result['startTime'].dt.weekday\n",
    "    result['hourCut'] = result['hour'].map(get_hour_cut)\n",
    "    result = result.drop(columns=['count', 'sum'])\n",
    "    # datetime -> int\n",
    "    return result\n",
    "def base_processing_test(data):\n",
    "    result = data\n",
    "    \n",
    "    result['day'] = result['startTime'].apply(lambda x: int(str(x)[8:10]))\n",
    "    result['startTime'] = pd.to_datetime(result['startTime'],format= '%Y-%m-%d %H:%M:%S')\n",
    "    result['weekday'] = result['startTime'].dt.weekday\n",
    "    #result['weekend'] = result['weekday'].apply(is_weekend)\n",
    "    result['hour'] = result['startTime'].apply(lambda x: int(str(x)[11:13]))\n",
    "    result['minute'] = result['startTime'].apply(lambda x: int(str(x)[14:15]+'0'))# hour+10min 10min最后可以删除\n",
    "    result['hourCut'] = result['hour'].map(get_hour_cut)\n",
    "    result = result.drop(columns='endTime')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the file: record_2019-01-01.csv\n",
      "Memory usage of properties dataframe is : 135.62892150878906  MB\n",
      "******************************\n",
      "Column:  stationID\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  deviceID\n",
      "dtype before:  int64\n",
      "dtype after:  uint16\n",
      "******************************\n",
      "******************************\n",
      "Column:  status\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  payType\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  70.23644256591797  MB\n",
      "This is  51.78574140720163 % of the initial size\n",
      "the file: record_2019-01-02.csv\n",
      "Memory usage of properties dataframe is : 126.91683959960938  MB\n",
      "******************************\n",
      "Column:  stationID\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  deviceID\n",
      "dtype before:  int64\n",
      "dtype after:  uint16\n",
      "******************************\n",
      "******************************\n",
      "Column:  status\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  payType\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  65.72482872009277  MB\n",
      "This is  51.78574326892951 % of the initial size\n",
      "the file: record_2019-01-03.csv\n",
      "Memory usage of properties dataframe is : 122.4846420288086  MB\n",
      "******************************\n",
      "Column:  stationID\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  deviceID\n",
      "dtype before:  int64\n",
      "dtype after:  uint16\n",
      "******************************\n",
      "******************************\n",
      "Column:  status\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  payType\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  63.42958354949951  MB\n",
      "This is  51.785744317708634 % of the initial size\n",
      "the file: record_2019-01-04.csv\n",
      "Memory usage of properties dataframe is : 129.44720458984375  MB\n",
      "******************************\n",
      "Column:  stationID\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  deviceID\n",
      "dtype before:  int64\n",
      "dtype after:  uint16\n",
      "******************************\n",
      "******************************\n",
      "Column:  status\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  payType\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  67.03519630432129  MB\n",
      "This is  51.78574270238106 % of the initial size\n",
      "the file: record_2019-01-05.csv\n",
      "Memory usage of properties dataframe is : 107.7691650390625  MB\n",
      "******************************\n",
      "Column:  stationID\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  deviceID\n",
      "dtype before:  int64\n",
      "dtype after:  uint16\n",
      "******************************\n",
      "******************************\n",
      "Column:  status\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  payType\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  55.80906867980957  MB\n",
      "This is  51.7857484184653 % of the initial size\n",
      "the file: record_2019-01-06.csv\n",
      "Memory usage of properties dataframe is : 104.04833221435547  MB\n",
      "******************************\n",
      "Column:  stationID\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  deviceID\n",
      "dtype before:  int64\n",
      "dtype after:  uint16\n",
      "******************************\n",
      "******************************\n",
      "Column:  status\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  payType\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  53.882208824157715  MB\n",
      "This is  51.78574963907363 % of the initial size\n",
      "the file: record_2019-01-07.csv\n",
      "Memory usage of properties dataframe is : 120.56005859375  MB\n",
      "******************************\n",
      "Column:  stationID\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  deviceID\n",
      "dtype before:  int64\n",
      "dtype after:  uint16\n",
      "******************************\n",
      "******************************\n",
      "Column:  status\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  payType\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  62.43292427062988  MB\n",
      "This is  51.78574479713009 % of the initial size\n",
      "the file: record_2019-01-08.csv\n",
      "Memory usage of properties dataframe is : 123.09117126464844  MB\n",
      "******************************\n",
      "Column:  stationID\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  deviceID\n",
      "dtype before:  int64\n",
      "dtype after:  uint16\n",
      "******************************\n",
      "******************************\n",
      "Column:  status\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  payType\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  63.74367904663086  MB\n",
      "This is  51.7857441697266 % of the initial size\n",
      "the file: record_2019-01-09.csv\n",
      "Memory usage of properties dataframe is : 121.84334564208984  MB\n",
      "******************************\n",
      "Column:  stationID\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  deviceID\n",
      "dtype before:  int64\n",
      "dtype after:  uint16\n",
      "******************************\n",
      "******************************\n",
      "Column:  status\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  payType\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  63.09748363494873  MB\n",
      "This is  51.785744475775616 % of the initial size\n",
      "the file: record_2019-01-10.csv\n",
      "Memory usage of properties dataframe is : 123.76958465576172  MB\n",
      "******************************\n",
      "Column:  stationID\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  deviceID\n",
      "dtype before:  int64\n",
      "dtype after:  uint16\n",
      "******************************\n",
      "******************************\n",
      "Column:  status\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  payType\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  64.09500026702881  MB\n",
      "This is  51.78574400592453 % of the initial size\n",
      "the file: record_2019-01-11.csv\n",
      "Memory usage of properties dataframe is : 133.6138153076172  MB\n",
      "******************************\n",
      "Column:  stationID\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  deviceID\n",
      "dtype before:  int64\n",
      "dtype after:  uint16\n",
      "******************************\n",
      "******************************\n",
      "Column:  status\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  payType\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  69.19290542602539  MB\n",
      "This is  51.78574181623625 % of the initial size\n",
      "the file: record_2019-01-12.csv\n",
      "Memory usage of properties dataframe is : 115.81388854980469  MB\n",
      "******************************\n",
      "Column:  stationID\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  deviceID\n",
      "dtype before:  int64\n",
      "dtype after:  uint16\n",
      "******************************\n",
      "******************************\n",
      "Column:  status\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  payType\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  59.9750862121582  MB\n",
      "This is  51.78574604751871 % of the initial size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the file: record_2019-01-13.csv\n",
      "Memory usage of properties dataframe is : 110.20756530761719  MB\n",
      "******************************\n",
      "Column:  stationID\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  deviceID\n",
      "dtype before:  int64\n",
      "dtype after:  uint16\n",
      "******************************\n",
      "******************************\n",
      "Column:  status\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  payType\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  57.07181167602539  MB\n",
      "This is  51.78574766326026 % of the initial size\n",
      "the file: record_2019-01-14.csv\n",
      "Memory usage of properties dataframe is : 128.0226058959961  MB\n",
      "******************************\n",
      "Column:  stationID\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  deviceID\n",
      "dtype before:  int64\n",
      "dtype after:  uint16\n",
      "******************************\n",
      "******************************\n",
      "Column:  status\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  payType\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  66.29745769500732  MB\n",
      "This is  51.78574301859354 % of the initial size\n",
      "the file: record_2019-01-15.csv\n",
      "Memory usage of properties dataframe is : 123.16716766357422  MB\n",
      "******************************\n",
      "Column:  stationID\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  deviceID\n",
      "dtype before:  int64\n",
      "dtype after:  uint16\n",
      "******************************\n",
      "******************************\n",
      "Column:  status\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  payType\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  63.783034324645996  MB\n",
      "This is  51.785744151287616 % of the initial size\n",
      "the file: record_2019-01-16.csv\n",
      "Memory usage of properties dataframe is : 129.08495330810547  MB\n",
      "******************************\n",
      "Column:  stationID\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  deviceID\n",
      "dtype before:  int64\n",
      "dtype after:  uint16\n",
      "******************************\n",
      "******************************\n",
      "Column:  status\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  payType\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  66.84760189056396  MB\n",
      "This is  51.78574278212679 % of the initial size\n",
      "the file: record_2019-01-17.csv\n",
      "Memory usage of properties dataframe is : 132.1672134399414  MB\n",
      "******************************\n",
      "Column:  stationID\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  deviceID\n",
      "dtype before:  int64\n",
      "dtype after:  uint16\n",
      "******************************\n",
      "******************************\n",
      "Column:  status\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  payType\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  68.443772315979  MB\n",
      "This is  51.785742117564425 % of the initial size\n",
      "the file: record_2019-01-18.csv\n",
      "Memory usage of properties dataframe is : 142.29454803466797  MB\n",
      "******************************\n",
      "Column:  stationID\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  deviceID\n",
      "dtype before:  int64\n",
      "dtype after:  uint16\n",
      "******************************\n",
      "******************************\n",
      "Column:  status\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  payType\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  73.6882848739624  MB\n",
      "This is  51.785740136726346 % of the initial size\n",
      "the file: record_2019-01-19.csv\n",
      "Memory usage of properties dataframe is : 117.991455078125  MB\n",
      "******************************\n",
      "Column:  stationID\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  deviceID\n",
      "dtype before:  int64\n",
      "dtype after:  uint16\n",
      "******************************\n",
      "******************************\n",
      "Column:  status\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  payType\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  61.10275459289551  MB\n",
      "This is  51.78574546134539 % of the initial size\n",
      "the file: record_2019-01-20.csv\n",
      "Memory usage of properties dataframe is : 112.88068389892578  MB\n",
      "******************************\n",
      "Column:  stationID\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  deviceID\n",
      "dtype before:  int64\n",
      "dtype after:  uint16\n",
      "******************************\n",
      "******************************\n",
      "Column:  status\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  payType\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  58.45610523223877  MB\n",
      "This is  51.78574687284922 % of the initial size\n",
      "the file: record_2019-01-21.csv\n",
      "Memory usage of properties dataframe is : 131.69649505615234  MB\n",
      "******************************\n",
      "Column:  stationID\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  deviceID\n",
      "dtype before:  int64\n",
      "dtype after:  uint16\n",
      "******************************\n",
      "******************************\n",
      "Column:  status\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  payType\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  68.20000743865967  MB\n",
      "This is  51.78574221704287 % of the initial size\n",
      "the file: record_2019-01-22.csv\n",
      "Memory usage of properties dataframe is : 132.2491912841797  MB\n",
      "******************************\n",
      "Column:  stationID\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  deviceID\n",
      "dtype before:  int64\n",
      "dtype after:  uint16\n",
      "******************************\n",
      "******************************\n",
      "Column:  status\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  payType\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  68.48622512817383  MB\n",
      "This is  51.785742100312184 % of the initial size\n",
      "the file: record_2019-01-23.csv\n",
      "Memory usage of properties dataframe is : 134.794189453125  MB\n",
      "******************************\n",
      "Column:  stationID\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  deviceID\n",
      "dtype before:  int64\n",
      "dtype after:  uint16\n",
      "******************************\n",
      "******************************\n",
      "Column:  status\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  payType\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  69.80417060852051  MB\n",
      "This is  51.785741575155264 % of the initial size\n",
      "the file: record_2019-01-24.csv\n",
      "Memory usage of properties dataframe is : 134.442138671875  MB\n",
      "******************************\n",
      "Column:  stationID\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  deviceID\n",
      "dtype before:  int64\n",
      "dtype after:  uint16\n",
      "******************************\n",
      "******************************\n",
      "Column:  status\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  payType\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  69.62185859680176  MB\n",
      "This is  51.78574164661552 % of the initial size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the file: record_2019-01-25.csv\n",
      "Memory usage of properties dataframe is : 137.58303833007812  MB\n",
      "******************************\n",
      "Column:  stationID\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  deviceID\n",
      "dtype before:  int64\n",
      "dtype after:  uint16\n",
      "******************************\n",
      "******************************\n",
      "Column:  status\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  payType\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  71.2483959197998  MB\n",
      "This is  51.785741021990226 % of the initial size\n",
      "Memory usage of properties dataframe is : 128.43527221679688  MB\n",
      "******************************\n",
      "Column:  stationID\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  deviceID\n",
      "dtype before:  int64\n",
      "dtype after:  uint16\n",
      "******************************\n",
      "******************************\n",
      "Column:  status\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  payType\n",
      "dtype before:  int64\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  66.51115989685059  MB\n",
      "This is  51.785742926273954 % of the initial size\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame()\n",
    "for file in os.listdir(TRAIN_PATH):\n",
    "    print(f'the file: {file}')\n",
    "    temp = read_data(os.path.join(TRAIN_PATH, file))\n",
    "    temp = base_processing(temp)\n",
    "    data = pd.concat([data, temp],ignore_index=True)\n",
    "    del temp\n",
    "test_name = os.path.join(TEST_A_PATH, 'testA_record_2019-01-28.csv')\n",
    "test_28 = read_data(test_name)\n",
    "test_28 = base_processing(test_28)\n",
    "data = pd.concat([data, test_28],ignore_index=True)\n",
    "test_name = os.path.join(TEST_A_PATH, 'testA_submit_2019-01-29.csv')\n",
    "test = pd.read_csv(test_name)\n",
    "test = base_processing_test(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 剔除周末,并修改为连续时间\n",
    "data = data[(data.day!=5)&(data.day!=6)]\n",
    "data = data[(data.day!=12)&(data.day!=13)]\n",
    "data = data[(data.day!=19)&(data.day!=20)]\n",
    "data = data[(data.day!=26)&(data.day!=27)]\n",
    "\n",
    "def fix_day(d):\n",
    "    if d in [1,2,3,4]:\n",
    "        return d\n",
    "    elif d in [7,8,9,10,11]:\n",
    "        return d - 2\n",
    "    elif d in [14,15,16,17,18]:\n",
    "        return d - 4\n",
    "    elif d in [21,22,23,24,25]:\n",
    "        return d - 6\n",
    "    elif d in [28]:\n",
    "        return d - 8\n",
    "data['day'] = data['day'].apply(fix_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = test.drop(['startTime'], axis=1)\n",
    "data = pd.concat([data,test], axis=0, ignore_index=True)\n",
    "\n",
    "stat_columns = ['inNums','outNums']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_refer_day(d):\n",
    "    if d == 20:\n",
    "        return 29\n",
    "    else:\n",
    "        return d + 1\n",
    "# 1->1 1->2 2->3...20->29\n",
    "tmp = data.copy()\n",
    "tmp_df = tmp[tmp.day==1]\n",
    "tmp_df['day'] = tmp_df['day'] - 1\n",
    "tmp = pd.concat([tmp, tmp_df], axis=0, ignore_index=True)\n",
    "tmp['day'] = tmp['day'].apply(get_refer_day)\n",
    "\n",
    "for f in stat_columns:\n",
    "    tmp.rename(columns={f: f+'_last'}, inplace=True) \n",
    "    \n",
    "tmp = tmp[['stationID','day','hour','minute','inNums_last','outNums_last']]\n",
    "# 相当于把前一天的innum和outnum加在了当天行\n",
    "# 但是要求比较严格 必须是同十分钟内的\n",
    "data = data.merge(tmp, on=['stationID','day','hour','minute'], how='left')\n",
    "data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = data.groupby(['stationID','weekday','hour','minute'], as_index=False)['inNums'].agg({\n",
    "                                                                        'inNums_whm_max'    : 'max',\n",
    "                                                                        'inNums_whm_min'    : 'min',\n",
    "                                                                        'inNums_whm_mean'   : 'mean'\n",
    "                                                                        })\n",
    "data = data.merge(tmp, on=['stationID','weekday','hour','minute'], how='left')\n",
    "\n",
    "tmp = data.groupby(['stationID','weekday','hour','minute'], as_index=False)['outNums'].agg({\n",
    "                                                                        'outNums_whm_max'    : 'max',\n",
    "                                                                        'outNums_whm_min'    : 'min',\n",
    "                                                                        'outNums_whm_mean'   : 'mean'\n",
    "                                                                        })\n",
    "data = data.merge(tmp, on=['stationID','weekday','hour','minute'], how='left')\n",
    "\n",
    "tmp = data.groupby(['stationID','weekday','hour'], as_index=False)['inNums'].agg({\n",
    "                                                                        'inNums_wh_max'    : 'max',\n",
    "                                                                        'inNums_wh_min'    : 'min',\n",
    "                                                                        'inNums_wh_mean'   : 'mean'\n",
    "                                                                        })\n",
    "data = data.merge(tmp, on=['stationID','weekday','hour'], how='left')\n",
    "\n",
    "tmp = data.groupby(['stationID','weekday','hour'], as_index=False)['outNums'].agg({\n",
    "                                                                        #'outNums_wh_max'    : 'max',\n",
    "                                                                        #'outNums_wh_min'    : 'min',\n",
    "                                                                        'outNums_wh_mean'   : 'mean'\n",
    "                                                                        })\n",
    "data = data.merge(tmp, on=['stationID','weekday','hour'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_day(d):\n",
    "    if d in [1,2,3,4]:\n",
    "        return d\n",
    "    elif d in [5,6,7,8,9]:\n",
    "        return d + 2\n",
    "    elif d in [10,11,12,13,14]:\n",
    "        return d + 4\n",
    "    elif d in [15,16,17,18,19]:\n",
    "        return d + 6\n",
    "    elif d == 20:\n",
    "        return d + 8\n",
    "    else:\n",
    "        return d\n",
    "    \n",
    "data = data.drop(columns='startTime')\n",
    "all_columns = [f for f in data.columns if f not in ['weekend','inNums','outNums']]\n",
    "### all data\n",
    "all_data = data[data.day!=29]\n",
    "all_data['day'] = all_data['day'].apply(recover_day)\n",
    "X_data = all_data[all_columns].values\n",
    "\n",
    "train = data[data.day <20]\n",
    "train['day'] = train['day'].apply(recover_day)\n",
    "X_train = train[all_columns].values\n",
    "\n",
    "valid = data[data.day==20]\n",
    "valid['day'] = valid['day'].apply(recover_day)\n",
    "X_valid = valid[all_columns].values\n",
    "\n",
    "test  = data[data.day==29]\n",
    "X_test = test[all_columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttrain's l1: 10.5348\tvalid's l1: 13.5242\n",
      "[2000]\ttrain's l1: 9.90886\tvalid's l1: 13.2522\n",
      "[3000]\ttrain's l1: 9.49161\tvalid's l1: 13.1366\n",
      "Early stopping, best iteration is:\n",
      "[3065]\ttrain's l1: 9.46478\tvalid's l1: 13.1265\n",
      "[1000]\ttrain's l1: 10.6495\n",
      "[2000]\ttrain's l1: 10.0046\n",
      "[3000]\ttrain's l1: 9.58309\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's l1: 11.9288\tvalid_1's l1: 15.6208\n",
      "[2000]\ttraining's l1: 11.2864\tvalid_1's l1: 15.2843\n",
      "[3000]\ttraining's l1: 10.8119\tvalid_1's l1: 15.1318\n",
      "[4000]\ttraining's l1: 10.4418\tvalid_1's l1: 15.0495\n",
      "[5000]\ttraining's l1: 10.1308\tvalid_1's l1: 15.0137\n",
      "[6000]\ttraining's l1: 9.85554\tvalid_1's l1: 14.9984\n",
      "Early stopping, best iteration is:\n",
      "[5899]\ttraining's l1: 9.88199\tvalid_1's l1: 14.9961\n",
      "[1000]\ttrain's l1: 11.9988\n",
      "[2000]\ttrain's l1: 11.3378\n",
      "[3000]\ttrain's l1: 10.8754\n",
      "[4000]\ttrain's l1: 10.5179\n",
      "[5000]\ttrain's l1: 10.2114\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-cf5b07cbed48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'outNums'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m \u001b[0msub\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/Metro_testA/testA_submit_2019-01-29.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[0msub\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'inNums'\u001b[0m\u001b[1;33m]\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'inNums'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[0msub\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'outNums'\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'outNums'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'path' is not defined"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae',\n",
    "    'num_leaves': 63,\n",
    "    'learning_rate': 0.01,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.9,\n",
    "    'bagging_seed':0,\n",
    "    'bagging_freq': 1,\n",
    "    'verbose': 1,\n",
    "    'reg_alpha':1,\n",
    "    'reg_lambda':2\n",
    "}\n",
    "\n",
    "######################################################inNums\n",
    "y_train = train['inNums']\n",
    "y_valid = valid['inNums']\n",
    "y_data  = all_data['inNums']\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_evals = lgb.Dataset(X_valid, y_valid , reference=lgb_train)\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=100000,\n",
    "                valid_sets=[lgb_train,lgb_evals],\n",
    "                valid_names=['train','valid'],\n",
    "                early_stopping_rounds=200,\n",
    "                verbose_eval=1000,\n",
    "                )\n",
    "\n",
    "### all_data\n",
    "lgb_train = lgb.Dataset(X_data, y_data)\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=gbm.best_iteration,\n",
    "                valid_sets=[lgb_train],\n",
    "                valid_names=['train'],\n",
    "                verbose_eval=1000,\n",
    "                )\n",
    "test['inNums'] = gbm.predict(X_test)\n",
    "\n",
    "######################################################outNums\n",
    "y_train = train['outNums']\n",
    "y_valid = valid['outNums']\n",
    "y_data  = all_data['outNums']\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_evals = lgb.Dataset(X_valid, y_valid , reference=lgb_train)\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=10000,\n",
    "                valid_sets=[lgb_train,lgb_evals],\n",
    "                #valid_names=['train','valid'],\n",
    "                early_stopping_rounds=200,\n",
    "                verbose_eval=1000,\n",
    "                )\n",
    "\n",
    "### all_data\n",
    "lgb_train = lgb.Dataset(X_data, y_data)\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=gbm.best_iteration,\n",
    "                valid_sets=[lgb_train],\n",
    "                valid_names=['train'],\n",
    "                verbose_eval=1000,\n",
    "                )\n",
    "test['outNums'] = gbm.predict(X_test)\n",
    "\n",
    "sub = pd.read_csv(path + '/Metro_testA/testA_submit_2019-01-29.csv')\n",
    "sub['inNums']   = test['inNums'].values\n",
    "sub['outNums']  = test['outNums'].values\n",
    "# 结果修正\n",
    "sub.loc[sub.inNums<0 , 'inNums']  = 0\n",
    "sub.loc[sub.outNums<0, 'outNums'] = 0\n",
    "sub[['stationID', 'startTime', 'endTime', 'inNums', 'outNums']].to_csv('output/sub_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 17.7855\tvalid_1's l1: 18.4451\n",
      "[20000]\ttraining's l1: 16.6919\tvalid_1's l1: 17.5794\n",
      "[30000]\ttraining's l1: 16.0998\tvalid_1's l1: 17.1156\n",
      "[40000]\ttraining's l1: 15.7\tvalid_1's l1: 16.79\n",
      "[50000]\ttraining's l1: 15.3908\tvalid_1's l1: 16.5462\n",
      "[60000]\ttraining's l1: 15.1201\tvalid_1's l1: 16.3432\n",
      "Early stopping, best iteration is:\n",
      "[68377]\ttraining's l1: 14.9415\tvalid_1's l1: 16.2217\n",
      "fold: 1\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 17.7155\tvalid_1's l1: 18.8802\n",
      "[20000]\ttraining's l1: 16.67\tvalid_1's l1: 18.1087\n",
      "[30000]\ttraining's l1: 16.0754\tvalid_1's l1: 17.6917\n",
      "[40000]\ttraining's l1: 15.6662\tvalid_1's l1: 17.3725\n",
      "Early stopping, best iteration is:\n",
      "[48434]\ttraining's l1: 15.3766\tvalid_1's l1: 17.1783\n",
      "fold: 2\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 17.6973\tvalid_1's l1: 18.4418\n",
      "[20000]\ttraining's l1: 16.6015\tvalid_1's l1: 17.5866\n",
      "[30000]\ttraining's l1: 16.0013\tvalid_1's l1: 17.1268\n",
      "[40000]\ttraining's l1: 15.6267\tvalid_1's l1: 16.8632\n",
      "[50000]\ttraining's l1: 15.3026\tvalid_1's l1: 16.6186\n",
      "[60000]\ttraining's l1: 15.0557\tvalid_1's l1: 16.4685\n",
      "[70000]\ttraining's l1: 14.8369\tvalid_1's l1: 16.3284\n",
      "Early stopping, best iteration is:\n",
      "[76196]\ttraining's l1: 14.7166\tvalid_1's l1: 16.2498\n",
      "fold: 3\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 17.8008\tvalid_1's l1: 18.7868\n",
      "[20000]\ttraining's l1: 16.697\tvalid_1's l1: 17.9008\n",
      "[30000]\ttraining's l1: 16.1038\tvalid_1's l1: 17.3914\n",
      "[40000]\ttraining's l1: 15.6793\tvalid_1's l1: 17.0928\n",
      "[50000]\ttraining's l1: 15.3521\tvalid_1's l1: 16.8554\n",
      "[60000]\ttraining's l1: 15.0999\tvalid_1's l1: 16.7033\n",
      "[70000]\ttraining's l1: 14.875\tvalid_1's l1: 16.5379\n",
      "Early stopping, best iteration is:\n",
      "[72754]\ttraining's l1: 14.8224\tvalid_1's l1: 16.5019\n",
      "fold: 4\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 17.7086\tvalid_1's l1: 18.7683\n",
      "[20000]\ttraining's l1: 16.626\tvalid_1's l1: 17.904\n",
      "[30000]\ttraining's l1: 16.0125\tvalid_1's l1: 17.4682\n",
      "[40000]\ttraining's l1: 15.5781\tvalid_1's l1: 17.1116\n",
      "[50000]\ttraining's l1: 15.2662\tvalid_1's l1: 16.8779\n",
      "Early stopping, best iteration is:\n",
      "[57100]\ttraining's l1: 15.0825\tvalid_1's l1: 16.7821\n",
      "fold: 5\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 17.6604\tvalid_1's l1: 17.9811\n",
      "[20000]\ttraining's l1: 16.5956\tvalid_1's l1: 17.1683\n",
      "[30000]\ttraining's l1: 16.0311\tvalid_1's l1: 16.745\n",
      "[40000]\ttraining's l1: 15.6104\tvalid_1's l1: 16.4602\n",
      "[50000]\ttraining's l1: 15.2937\tvalid_1's l1: 16.2367\n",
      "Early stopping, best iteration is:\n",
      "[51085]\ttraining's l1: 15.2641\tvalid_1's l1: 16.2152\n",
      "fold: 6\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 17.7865\tvalid_1's l1: 18.7055\n",
      "[20000]\ttraining's l1: 16.7055\tvalid_1's l1: 17.8642\n",
      "[30000]\ttraining's l1: 16.081\tvalid_1's l1: 17.399\n",
      "Early stopping, best iteration is:\n",
      "[35663]\ttraining's l1: 15.8364\tvalid_1's l1: 17.2191\n",
      "fold: 7\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 17.7684\tvalid_1's l1: 18.3234\n",
      "[20000]\ttraining's l1: 16.6982\tvalid_1's l1: 17.517\n",
      "[30000]\ttraining's l1: 16.1016\tvalid_1's l1: 17.0967\n",
      "Early stopping, best iteration is:\n",
      "[36140]\ttraining's l1: 15.8514\tvalid_1's l1: 16.9092\n",
      "fold: 8\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 17.8099\tvalid_1's l1: 18.6017\n",
      "[20000]\ttraining's l1: 16.7047\tvalid_1's l1: 17.7048\n",
      "[30000]\ttraining's l1: 16.1143\tvalid_1's l1: 17.2328\n",
      "[40000]\ttraining's l1: 15.6676\tvalid_1's l1: 16.9079\n",
      "[50000]\ttraining's l1: 15.3512\tvalid_1's l1: 16.6661\n",
      "Early stopping, best iteration is:\n",
      "[59093]\ttraining's l1: 15.1192\tvalid_1's l1: 16.5027\n",
      "fold: 9\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 17.7263\tvalid_1's l1: 18.3009\n",
      "[20000]\ttraining's l1: 16.6539\tvalid_1's l1: 17.4966\n",
      "[30000]\ttraining's l1: 16.1017\tvalid_1's l1: 17.1325\n",
      "[40000]\ttraining's l1: 15.6932\tvalid_1's l1: 16.8419\n",
      "Early stopping, best iteration is:\n",
      "[42410]\ttraining's l1: 15.604\tvalid_1's l1: 16.7724\n",
      "fold: 10\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 17.8123\tvalid_1's l1: 18.5066\n",
      "[20000]\ttraining's l1: 16.7221\tvalid_1's l1: 17.617\n",
      "[30000]\ttraining's l1: 16.1005\tvalid_1's l1: 17.1238\n",
      "[40000]\ttraining's l1: 15.7021\tvalid_1's l1: 16.8687\n",
      "[50000]\ttraining's l1: 15.3868\tvalid_1's l1: 16.6551\n",
      "Early stopping, best iteration is:\n",
      "[50227]\ttraining's l1: 15.38\tvalid_1's l1: 16.6401\n",
      "fold: 11\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 17.7168\tvalid_1's l1: 18.6534\n",
      "[20000]\ttraining's l1: 16.6004\tvalid_1's l1: 17.7181\n",
      "[30000]\ttraining's l1: 16.0094\tvalid_1's l1: 17.2701\n",
      "[40000]\ttraining's l1: 15.6125\tvalid_1's l1: 16.9632\n",
      "[50000]\ttraining's l1: 15.2979\tvalid_1's l1: 16.7434\n",
      "Early stopping, best iteration is:\n",
      "[52167]\ttraining's l1: 15.2344\tvalid_1's l1: 16.6918\n",
      "fold: 12\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 17.771\tvalid_1's l1: 18.5839\n",
      "[20000]\ttraining's l1: 16.6898\tvalid_1's l1: 17.713\n",
      "[30000]\ttraining's l1: 16.0906\tvalid_1's l1: 17.2494\n",
      "Early stopping, best iteration is:\n",
      "[37179]\ttraining's l1: 15.785\tvalid_1's l1: 16.9976\n",
      "fold: 13\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 17.811\tvalid_1's l1: 19.1138\n",
      "[20000]\ttraining's l1: 16.7177\tvalid_1's l1: 18.2012\n",
      "[30000]\ttraining's l1: 16.1524\tvalid_1's l1: 17.7373\n",
      "[40000]\ttraining's l1: 15.7327\tvalid_1's l1: 17.4078\n",
      "[50000]\ttraining's l1: 15.3976\tvalid_1's l1: 17.1404\n",
      "[60000]\ttraining's l1: 15.1349\tvalid_1's l1: 16.9536\n",
      "Early stopping, best iteration is:\n",
      "[63836]\ttraining's l1: 15.0547\tvalid_1's l1: 16.9069\n",
      "fold: 14\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 17.807\tvalid_1's l1: 18.1595\n",
      "[20000]\ttraining's l1: 16.7183\tvalid_1's l1: 17.3692\n",
      "[30000]\ttraining's l1: 16.1057\tvalid_1's l1: 16.9344\n",
      "[40000]\ttraining's l1: 15.7067\tvalid_1's l1: 16.6759\n",
      "Early stopping, best iteration is:\n",
      "[47769]\ttraining's l1: 15.4565\tvalid_1's l1: 16.4775\n",
      "mae error: 18.649327097308436\n",
      "fold: 0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.3058\tvalid_1's l1: 21.2697\n",
      "[20000]\ttraining's l1: 19.2489\tvalid_1's l1: 20.4083\n",
      "[30000]\ttraining's l1: 18.678\tvalid_1's l1: 20.0461\n",
      "Early stopping, best iteration is:\n",
      "[36445]\ttraining's l1: 18.4236\tvalid_1's l1: 19.8645\n",
      "fold: 1\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.1299\tvalid_1's l1: 21.3901\n",
      "[20000]\ttraining's l1: 19.1647\tvalid_1's l1: 20.6523\n",
      "[30000]\ttraining's l1: 18.6169\tvalid_1's l1: 20.3131\n",
      "Early stopping, best iteration is:\n",
      "[30772]\ttraining's l1: 18.5726\tvalid_1's l1: 20.2946\n",
      "fold: 2\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.219\tvalid_1's l1: 21.1263\n",
      "[20000]\ttraining's l1: 19.2206\tvalid_1's l1: 20.4309\n",
      "[30000]\ttraining's l1: 18.6628\tvalid_1's l1: 20.0133\n",
      "[40000]\ttraining's l1: 18.2616\tvalid_1's l1: 19.7033\n",
      "Early stopping, best iteration is:\n",
      "[41430]\ttraining's l1: 18.2166\tvalid_1's l1: 19.6704\n",
      "fold: 3\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.2985\tvalid_1's l1: 21.3414\n",
      "[20000]\ttraining's l1: 19.263\tvalid_1's l1: 20.5751\n",
      "[30000]\ttraining's l1: 18.6791\tvalid_1's l1: 20.1767\n",
      "[40000]\ttraining's l1: 18.2492\tvalid_1's l1: 19.8736\n",
      "Early stopping, best iteration is:\n",
      "[42291]\ttraining's l1: 18.1812\tvalid_1's l1: 19.8286\n",
      "fold: 4\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.2186\tvalid_1's l1: 21.5989\n",
      "[20000]\ttraining's l1: 19.2047\tvalid_1's l1: 20.8298\n",
      "[30000]\ttraining's l1: 18.6447\tvalid_1's l1: 20.4695\n",
      "[40000]\ttraining's l1: 18.2327\tvalid_1's l1: 20.1934\n",
      "[50000]\ttraining's l1: 17.9224\tvalid_1's l1: 19.9975\n",
      "Early stopping, best iteration is:\n",
      "[49777]\ttraining's l1: 17.9276\tvalid_1's l1: 19.9942\n",
      "fold: 5\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.1691\tvalid_1's l1: 20.4763\n",
      "[20000]\ttraining's l1: 19.1562\tvalid_1's l1: 19.7454\n",
      "[30000]\ttraining's l1: 18.6293\tvalid_1's l1: 19.4138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[36135]\ttraining's l1: 18.4048\tvalid_1's l1: 19.2452\n",
      "fold: 6\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.4968\tvalid_1's l1: 21.9708\n",
      "[20000]\ttraining's l1: 19.3832\tvalid_1's l1: 21.01\n",
      "[30000]\ttraining's l1: 18.7661\tvalid_1's l1: 20.5457\n",
      "[40000]\ttraining's l1: 18.3312\tvalid_1's l1: 20.2477\n",
      "Early stopping, best iteration is:\n",
      "[44793]\ttraining's l1: 18.1727\tvalid_1's l1: 20.1434\n",
      "fold: 7\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.1345\tvalid_1's l1: 21.195\n",
      "[20000]\ttraining's l1: 19.2395\tvalid_1's l1: 20.5554\n",
      "[30000]\ttraining's l1: 18.6795\tvalid_1's l1: 20.1952\n",
      "Early stopping, best iteration is:\n",
      "[37141]\ttraining's l1: 18.3883\tvalid_1's l1: 19.9632\n",
      "fold: 8\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.1996\tvalid_1's l1: 20.6351\n",
      "[20000]\ttraining's l1: 19.2325\tvalid_1's l1: 19.9794\n",
      "[30000]\ttraining's l1: 18.6968\tvalid_1's l1: 19.6628\n",
      "Early stopping, best iteration is:\n",
      "[34450]\ttraining's l1: 18.5288\tvalid_1's l1: 19.5576\n",
      "fold: 9\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.0874\tvalid_1's l1: 20.5675\n",
      "[20000]\ttraining's l1: 19.1821\tvalid_1's l1: 19.9058\n",
      "[30000]\ttraining's l1: 18.6347\tvalid_1's l1: 19.5048\n",
      "[40000]\ttraining's l1: 18.243\tvalid_1's l1: 19.2453\n",
      "Early stopping, best iteration is:\n",
      "[40086]\ttraining's l1: 18.2407\tvalid_1's l1: 19.2389\n",
      "fold: 10\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.2218\tvalid_1's l1: 20.7232\n",
      "[20000]\ttraining's l1: 19.23\tvalid_1's l1: 20.1093\n",
      "[30000]\ttraining's l1: 18.6723\tvalid_1's l1: 19.714\n",
      "Early stopping, best iteration is:\n",
      "[36160]\ttraining's l1: 18.4206\tvalid_1's l1: 19.5551\n",
      "fold: 11\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.2984\tvalid_1's l1: 21.4635\n",
      "[20000]\ttraining's l1: 19.2356\tvalid_1's l1: 20.6651\n",
      "[30000]\ttraining's l1: 18.6675\tvalid_1's l1: 20.2963\n",
      "Early stopping, best iteration is:\n",
      "[29423]\ttraining's l1: 18.6878\tvalid_1's l1: 20.2903\n",
      "fold: 12\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.1901\tvalid_1's l1: 20.3763\n",
      "[20000]\ttraining's l1: 19.1704\tvalid_1's l1: 19.7136\n",
      "[30000]\ttraining's l1: 18.6172\tvalid_1's l1: 19.3856\n",
      "Early stopping, best iteration is:\n",
      "[32665]\ttraining's l1: 18.4862\tvalid_1's l1: 19.3009\n",
      "fold: 13\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.3123\tvalid_1's l1: 21.1705\n",
      "[20000]\ttraining's l1: 19.2979\tvalid_1's l1: 20.5067\n",
      "[30000]\ttraining's l1: 18.7269\tvalid_1's l1: 20.0854\n",
      "Early stopping, best iteration is:\n",
      "[38883]\ttraining's l1: 18.3572\tvalid_1's l1: 19.8376\n",
      "fold: 14\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.2138\tvalid_1's l1: 21.4678\n",
      "[20000]\ttraining's l1: 19.1899\tvalid_1's l1: 20.7327\n",
      "[30000]\ttraining's l1: 18.6149\tvalid_1's l1: 20.2991\n",
      "[40000]\ttraining's l1: 18.2506\tvalid_1's l1: 20.0514\n",
      "Early stopping, best iteration is:\n",
      "[41980]\ttraining's l1: 18.1843\tvalid_1's l1: 20.0131\n",
      "mae error: 76.91464066284706\n"
     ]
    }
   ],
   "source": [
    "X_train = train[['stationID', 'date', 'startTime', 'weekday','hourCut']]\n",
    "y_train_1 = train['inNums']\n",
    "y_train_2 = train['outNums']\n",
    "X_test_28 = test_28[['stationID', 'date', 'startTime', 'weekday','hourCut']]\n",
    "y_test_28_1 = test_28['inNums']\n",
    "y_test_28_2 = test_28['outNums']\n",
    "X_test_29 = test_29[['stationID', 'date', 'startTime', 'weekday','hourCut']]\n",
    "params = {\n",
    "    'bagging_freq': 10,          \n",
    "    'bagging_fraction': 0.3,   'boost_from_average':'false',   \n",
    "    'boost': 'gbdt',             \n",
    "    #'feature_fraction': 0.0405,     \n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': -1,             'metric':'mae',                \n",
    "    'min_data_in_leaf': 80, \n",
    "    'num_leaves': 13,            \n",
    "    'num_threads': -1, \n",
    "    'objective': 'regression_l1',       'verbosity': 1,\n",
    "    'num_boost_round': 10000000\n",
    "}\n",
    "NFOLD = 15\n",
    "folds = KFold(n_splits=NFOLD, random_state=134, shuffle=True)\n",
    "val_lgb1 = np.zeros(len(X_train))\n",
    "pred_lgb1 = np.zeros(len(X_test_29))\n",
    "pred_28_1 = np.zeros(len(X_test_28))\n",
    "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train_1)):\n",
    "    print(f'fold: {n_fold}')\n",
    "    trn_data = lgb.Dataset(X_train.iloc[trn_idx], y_train_1[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train.iloc[val_idx], y_train_1[val_idx])\n",
    "    \n",
    "    reg_lgb1 = lgb.train(params, trn_data, num_boost_round=2000000, valid_sets=[trn_data, val_data], verbose_eval=10000, early_stopping_rounds=600)\n",
    "    #val_lgb1[val_idx] = reg_lgb1.predict(X_train.iloc[val_idx], num_iteration=reg_lgb.best_iteration)\n",
    "    pred_lgb1 += reg_lgb1.predict(X_test_29, num_iteration=reg_lgb1.best_iteration) / NFOLD\n",
    "    pred_28_1 += reg_lgb1.predict(X_test_28, num_iteration=reg_lgb1.best_iteration) / NFOLD \n",
    "print(f'mae error: {mean_absolute_error(pred_28_1, y_test_28_1)}')\n",
    "\n",
    "folds = KFold(n_splits=NFOLD, random_state=134, shuffle=True)\n",
    "val_lgb2 = np.zeros(len(X_train))\n",
    "pred_lgb2 = np.zeros(len(X_test_29))\n",
    "pred_28_2 = np.zeros(len(X_test_28))\n",
    "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train_2)):\n",
    "    print(f'fold: {n_fold}')\n",
    "    trn_data = lgb.Dataset(X_train.iloc[trn_idx], y_train_2[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train.iloc[val_idx], y_train_2[val_idx])\n",
    "    \n",
    "    reg_lgb2 = lgb.train(params, trn_data, num_boost_round=2000000, valid_sets=[trn_data, val_data], verbose_eval=10000, early_stopping_rounds=600)\n",
    "    #val_lgb2[val_idx] = reg_lgb2.predict(X_train.iloc[val_idx], num_iteration=reg_lgb.best_iteration)\n",
    "    pred_lgb2 += reg_lgb2.predict(X_test_29, num_iteration=reg_lgb2.best_iteration) / NFOLD\n",
    "    pred_28_2 += reg_lgb2.predict(X_test_28, num_iteration=reg_lgb2.best_iteration) / NFOLD \n",
    "print(f'mae error: {mean_absolute_error(pred_28_2, y_test_28_2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.3058\tvalid_1's l1: 21.2697\n",
      "[20000]\ttraining's l1: 19.2489\tvalid_1's l1: 20.4083\n",
      "[30000]\ttraining's l1: 18.678\tvalid_1's l1: 20.0461\n",
      "Early stopping, best iteration is:\n",
      "[36445]\ttraining's l1: 18.4236\tvalid_1's l1: 19.8645\n",
      "fold: 1\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.1299\tvalid_1's l1: 21.3901\n",
      "[20000]\ttraining's l1: 19.1647\tvalid_1's l1: 20.6523\n",
      "[30000]\ttraining's l1: 18.6169\tvalid_1's l1: 20.3131\n",
      "Early stopping, best iteration is:\n",
      "[30772]\ttraining's l1: 18.5726\tvalid_1's l1: 20.2946\n",
      "fold: 2\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.219\tvalid_1's l1: 21.1263\n",
      "[20000]\ttraining's l1: 19.2206\tvalid_1's l1: 20.4309\n",
      "[30000]\ttraining's l1: 18.6628\tvalid_1's l1: 20.0133\n",
      "[40000]\ttraining's l1: 18.2616\tvalid_1's l1: 19.7033\n",
      "Early stopping, best iteration is:\n",
      "[41430]\ttraining's l1: 18.2166\tvalid_1's l1: 19.6704\n",
      "fold: 3\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.2985\tvalid_1's l1: 21.3414\n",
      "[20000]\ttraining's l1: 19.263\tvalid_1's l1: 20.5751\n",
      "[30000]\ttraining's l1: 18.6791\tvalid_1's l1: 20.1767\n",
      "[40000]\ttraining's l1: 18.2492\tvalid_1's l1: 19.8736\n",
      "Early stopping, best iteration is:\n",
      "[42291]\ttraining's l1: 18.1812\tvalid_1's l1: 19.8286\n",
      "fold: 4\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.2186\tvalid_1's l1: 21.5989\n",
      "[20000]\ttraining's l1: 19.2047\tvalid_1's l1: 20.8298\n",
      "[30000]\ttraining's l1: 18.6447\tvalid_1's l1: 20.4695\n",
      "[40000]\ttraining's l1: 18.2327\tvalid_1's l1: 20.1934\n",
      "[50000]\ttraining's l1: 17.9224\tvalid_1's l1: 19.9975\n",
      "Early stopping, best iteration is:\n",
      "[49777]\ttraining's l1: 17.9276\tvalid_1's l1: 19.9942\n",
      "fold: 5\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.1691\tvalid_1's l1: 20.4763\n",
      "[20000]\ttraining's l1: 19.1562\tvalid_1's l1: 19.7454\n",
      "[30000]\ttraining's l1: 18.6293\tvalid_1's l1: 19.4138\n",
      "Early stopping, best iteration is:\n",
      "[36135]\ttraining's l1: 18.4048\tvalid_1's l1: 19.2452\n",
      "fold: 6\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.4968\tvalid_1's l1: 21.9708\n",
      "[20000]\ttraining's l1: 19.3832\tvalid_1's l1: 21.01\n",
      "[30000]\ttraining's l1: 18.7661\tvalid_1's l1: 20.5457\n",
      "[40000]\ttraining's l1: 18.3312\tvalid_1's l1: 20.2477\n",
      "Early stopping, best iteration is:\n",
      "[44793]\ttraining's l1: 18.1727\tvalid_1's l1: 20.1434\n",
      "fold: 7\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.1345\tvalid_1's l1: 21.195\n",
      "[20000]\ttraining's l1: 19.2395\tvalid_1's l1: 20.5554\n",
      "[30000]\ttraining's l1: 18.6795\tvalid_1's l1: 20.1952\n",
      "Early stopping, best iteration is:\n",
      "[37141]\ttraining's l1: 18.3883\tvalid_1's l1: 19.9632\n",
      "fold: 8\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.1996\tvalid_1's l1: 20.6351\n",
      "[20000]\ttraining's l1: 19.2325\tvalid_1's l1: 19.9794\n",
      "[30000]\ttraining's l1: 18.6968\tvalid_1's l1: 19.6628\n",
      "Early stopping, best iteration is:\n",
      "[34450]\ttraining's l1: 18.5288\tvalid_1's l1: 19.5576\n",
      "fold: 9\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.0874\tvalid_1's l1: 20.5675\n",
      "[20000]\ttraining's l1: 19.1821\tvalid_1's l1: 19.9058\n",
      "[30000]\ttraining's l1: 18.6347\tvalid_1's l1: 19.5048\n",
      "[40000]\ttraining's l1: 18.243\tvalid_1's l1: 19.2453\n",
      "Early stopping, best iteration is:\n",
      "[40086]\ttraining's l1: 18.2407\tvalid_1's l1: 19.2389\n",
      "fold: 10\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.2218\tvalid_1's l1: 20.7232\n",
      "[20000]\ttraining's l1: 19.23\tvalid_1's l1: 20.1093\n",
      "[30000]\ttraining's l1: 18.6723\tvalid_1's l1: 19.714\n",
      "Early stopping, best iteration is:\n",
      "[36160]\ttraining's l1: 18.4206\tvalid_1's l1: 19.5551\n",
      "fold: 11\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.2984\tvalid_1's l1: 21.4635\n",
      "[20000]\ttraining's l1: 19.2356\tvalid_1's l1: 20.6651\n",
      "[30000]\ttraining's l1: 18.6675\tvalid_1's l1: 20.2963\n",
      "Early stopping, best iteration is:\n",
      "[29423]\ttraining's l1: 18.6878\tvalid_1's l1: 20.2903\n",
      "fold: 12\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.1901\tvalid_1's l1: 20.3763\n",
      "[20000]\ttraining's l1: 19.1704\tvalid_1's l1: 19.7136\n",
      "[30000]\ttraining's l1: 18.6172\tvalid_1's l1: 19.3856\n",
      "Early stopping, best iteration is:\n",
      "[32665]\ttraining's l1: 18.4862\tvalid_1's l1: 19.3009\n",
      "fold: 13\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.3123\tvalid_1's l1: 21.1705\n",
      "[20000]\ttraining's l1: 19.2979\tvalid_1's l1: 20.5067\n",
      "[30000]\ttraining's l1: 18.7269\tvalid_1's l1: 20.0854\n",
      "Early stopping, best iteration is:\n",
      "[38883]\ttraining's l1: 18.3572\tvalid_1's l1: 19.8376\n",
      "fold: 14\n",
      "Training until validation scores don't improve for 600 rounds.\n",
      "[10000]\ttraining's l1: 20.2138\tvalid_1's l1: 21.4678\n",
      "[20000]\ttraining's l1: 19.1899\tvalid_1's l1: 20.7327\n",
      "[30000]\ttraining's l1: 18.6149\tvalid_1's l1: 20.2991\n",
      "[40000]\ttraining's l1: 18.2506\tvalid_1's l1: 20.0514\n",
      "Early stopping, best iteration is:\n",
      "[41980]\ttraining's l1: 18.1843\tvalid_1's l1: 20.0131\n",
      "mae error: 21.02257397201306\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=NFOLD, random_state=134, shuffle=True)\n",
    "val_lgb2 = np.zeros(len(X_train))\n",
    "pred_lgb2 = np.zeros(len(X_test_29))\n",
    "pred_28_2 = np.zeros(len(X_test_28))\n",
    "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train_2)):\n",
    "    print(f'fold: {n_fold}')\n",
    "    trn_data = lgb.Dataset(X_train.iloc[trn_idx], y_train_2[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train.iloc[val_idx], y_train_2[val_idx])\n",
    "    \n",
    "    reg_lgb2 = lgb.train(params, trn_data, num_boost_round=2000000, valid_sets=[trn_data, val_data], verbose_eval=10000, early_stopping_rounds=600)\n",
    "    #val_lgb2[val_idx] = reg_lgb2.predict(X_train.iloc[val_idx], num_iteration=reg_lgb.best_iteration)\n",
    "    pred_lgb2 += reg_lgb2.predict(X_test_29, num_iteration=reg_lgb2.best_iteration) / NFOLD\n",
    "    pred_28_2 += reg_lgb2.predict(X_test_28, num_iteration=reg_lgb2.best_iteration) / NFOLD \n",
    "print(f'mae error: {mean_absolute_error(pred_28_2, y_test_28_2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_29['inNums'] = pred_lgb1\n",
    "test_29['outNums'] = pred_lgb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_name = os.path.join(TEST_A_PATH, 'testA_submit_2019-01-29.csv')\n",
    "submit = pd.read_csv(submit_name) \n",
    "test_29['startTime'] = submit['startTime']\n",
    "test_29[['stationID', 'startTime', 'endTime', 'inNums', 'outNums']].to_csv(SUBMIT_PATH+'/lgb.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
